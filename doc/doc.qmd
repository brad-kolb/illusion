---
title: "The Illusion of Certainty in Meta-Analysis"
author: "Bradley Kolb"
format: pdf
embed-resources: true
editor: visual
fig-format: png
execute: 
  warning: false
  error: false
  cache: false
editor_options: 
  chunk_output_type: console
---

## Packages

```{r}
library(tidyverse)
library(here)
```

## Data generating process

The data generating process is an important concept in statistical modelling, and focusing on the assumed data generating process in random effects meta-analysis is the best way of understanding what is going on. This is especially true for clinicians, who have extensive background in the physical and life sciences (which work by hypothesizing models to explain observed data), but limited background in mathematics and statistical theory.

In a random effects meta-analysis of randomized trials of particular intervention, the total effect of an intervention in a specific trial is assumed to have two components. The first component is due to the intervention. The second component is due to everything other than the intervention that influences the outcome. The portion of the effect due to the intervention is assumed to be constant across all the trials. The portion of the effect due to everything else is assumed to be context dependent, varying across all the trials in a deterministic but multi-factorial way.

```{r}
unobserved_variables <- tibble(
  treatment_effect = 0.7,
  context_effect = sample(c(-0.3, 0.3, 0.7), 10, replace = TRUE),
  true_effect = treatment_effect + context_effect
)

print(unobserved_variables)
```

The total effect and its components are "data" but they aren't observable. The observed data, which are events versus non-events in the control and intervention arms of each trial, is generated in this way.

```{r}
outcomes <- unobserved_variables %>% 
  mutate(
    baseline_odds = exp(0),
    intervention_odds = baseline_odds + true_effect,
    events_control = rbinom(10, 100, plogis(baseline_odds)),
    nonevents_control = 100 - events_control,
    events_intervention = rbinom(10, 100, plogis(intervention_odds)),
    nonevents_intervention = 100 - events_intervention
    ) %>%
  select(events_control, nonevents_control, events_intervention, nonevents_intervention)

print(outcomes)
```

The "estimated" effect sizes are calculated from the observed data.

```{r}
observed_variables <- outcomes %>% 
  mutate(
    y = log(events_intervention) - 
      log(nonevents_intervention) - 
      (log(events_control) - log(nonevents_control)),
    se = sqrt(1/events_intervention + 1/(nonevents_intervention) 
                      + 1/events_control + 1/(nonevents_control))
  ) %>% 
  select(y, se)

print(observed_variables)
```

The data generating process as outlined above generates values for all of the following variables.

```{r}
variables <- bind_cols(
  unobserved_variables, observed_variables
)

print(variables)
```

## The random effects model

A random effects meta-analysis assumes the above data generating process and then asks how we can use the observed variables to estimate the unobserved variables.

In order to do this, we assume the following statistical model.

$$
\begin{align*}
\theta_j &= \mu + \mu_j \\
y_j &= \theta_j + \epsilon_j
\end{align*}
$$

Here, $\mu_j$ is a normally distributed error term with a mean of zero and a standard deviation equal to $\tau$, and $\epsilon_j$ is a normally distributed error term with a mean of zero and a standard deviation equal to the observed standard error of the data $\text{se_j}$. The error terms are independent.

What this means in practice is that context-dependent portions of the true underlying treatment effects cancel each other out in large data sets (as j goes to infinity, the mean of the $\theta_j$'s converges to $\mu$). This also holds for the observed treatment effects.

## Stan model

```{stan output.var = "compiled_model"}
#| eval: false

data {
  int<lower=0> J; // num studies
  array[J] int<lower=0> n_t; // num cases, treatment
  array[J] int<lower=0> r_t; // num events, treatment
  array[J] int<lower=0> n_c; // num cases, control
  array[J] int<lower=0> r_c; // num events, control
  
  int<lower=0> estimate_posterior; // switch for estimating posterior vs running prior predictive simulation
  int<lower=0> priors; // switch for checking sensitivity of posterior to alternative specification for priors
}
transformed data {
  array[J] real y; // log odds ratio for each study
  for (j in 1:J) {
    y[j] = log(r_t[j]) - log(n_t[j] - r_t[j]) 
    - (log(r_c[j]) - log(n_c[j] - r_c[j]));
  }
  
  array[J] real<lower=0> se; // standard error of y (inverse variance method)
  for (j in 1:J) {
    se[j] = sqrt(1.0 / r_t[j] + 1.0 / (n_t[j] - r_t[j]) 
    + 1.0 / r_c[j] + 1.0 / (n_c[j] - r_c[j]));
  }
}
parameters {
  real mu; // mean treatment effect
  real<lower=0> tau; // deviation of treatment effects from the mean
  vector<offset=mu,multiplier=tau>[J] theta; // trial-specific treatment effects
}
model {
  if (estimate_posterior == 1) {
  y[1:J] ~ normal(theta[1:J], se[1:J]);
  } 
  
  theta[1:J] ~ normal(mu, tau); 
  if (priors == 1) { // standard normal
    mu ~ std_normal(); 
    tau ~ std_normal(); 
  } else { // CDSR
    mu ~ student_t(3.8, 0, 0.48); 
    tau ~ lognormal(-1.44, 0.79); 
  }
}
generated quantities {
  // pooling metrics
  vector[J] se2 = square(to_vector(se)); // approximate sampling variance for each study
  real se2_hat = sum(se2) / J; // average approximate sampling variance across all studies
  real<lower=0> i2 = square(tau) / (square(tau) + se2_hat); // proportion of total variance in effect size estimate due to heterogeneity between studies rather than sampling error
  vector[J] p = 1 - (square(tau) / (square(tau) + se2)); // proportion of variance in the trial_specific effect size estimate that is due to the true effect size rather than sampling error
  
  // posterior predictive distribution
  real theta_new = normal_rng(mu, tau); 
  
  // event probabilities 
  real mu_gt_0 = mu > 0;
  real theta_new_gt_0 = theta_new > 0;
  
  // Universe of 100 possible future studies
  array[100] real theta_100;
  for (i in 1:100) {
    theta_100[i] = normal_rng(mu, tau);
  }
}

```

## Experiment 1: variance

```{r}
#| echo: false
#| fig-width: 6
#| fig-height: 4
probs_df <- readRDS(here::here("experiment_one/probs.RDS"))
colors <- c("#E69F00", "#56B4E9", "#009E73", 
                "#F0E442", "#0072B2", "#D55E00", 
                "#CC79A7", "#000000")
par(mar = c(4, 4, 3, 2))
plot(probs_df$mu_gt_0, probs_df$theta_new_gt_0,
     xlab = expression(P(mu > 0)), 
     ylab = expression(P(theta[new] > 0)),
     main = "Average effect size vs. predicted effect size",
     col = colors[probs_df$condition],  
     pch = 19,
     cex = 0.75)
abline(0, 1, lty = 2)
abline(v = .975, lty = 3)
abline(h = .975, lty = 3)
legend("bottomright", 
       legend = c("Low τ", "Moderate τ", "High τ"),
       col = colors,  
       pch = 19)

```

```{r}
#| echo: false
results_low <- readRDS(here::here("experiment_one/results_low.RDS"))
mu_intervals <- lapply(results_low, function(x) {
  mu_samples <- x$samples$mu
  c(mean = mean(mu_samples),
    lower = quantile(mu_samples, 0.025),
    upper = quantile(mu_samples, 0.975))
}) %>%
  do.call(rbind, .) %>%
  as.data.frame() 


plot(NA, NA, 
     ylim = c(-1,1.75),
     xlim = c(0, nrow(mu_intervals)),
     xaxt = "n",
     ylab = "Effect Size",
     xlab = "Simulation",
     main = "μ posterior intervals, low tau")
# label first, middle and last simulation
axis(1, at=c(1, floor(nrow(mu_intervals)/2), nrow(mu_intervals)), 
     labels=c(1, floor(nrow(mu_intervals)/2), nrow(mu_intervals)))


abline(h = 0.7, lty = 2, col = "red")
abline(h = 0, lty = 2, col = "gray")

for(i in 1:nrow(mu_intervals)) {
  segments(i, mu_intervals$lower[i], i, mu_intervals$upper[i])
  points(i, mu_intervals$mean[i], pch = 20, cex = 1)
}

legend("bottomleft", 
       legend = c("Truth","Significance"),
       col = c("red","grey"),
       lty = 2,
       pt.cex = 0.7,
       bty = "n") 
```

## Experiment 2: trials

```{r}
#| echo: false
#| fig-width: 6
#| fig-height: 4
probs_df <- readRDS(here::here("experiment_two.RDS"))
colors <- c("#E69F00", "#56B4E9", "#009E73", 
            "#F0E442", "#0072B2", "#D55E00", 
            "#CC79A7", "#000000")
par(mar = c(4, 4, 3, 2))
plot(probs_df$mu_gt_0, probs_df$theta_new_gt_0,
     xlab = expression(P(mu > 0)), 
     ylab = expression(P(theta[new] > 0)),
     main = "Average effect size vs. predicted effect size",
     col = colors[probs_df$condition],  
     pch = 19,
     cex = 0.75)
abline(0, 1, lty = 2)
abline(v = .975, lty = 3)
abline(h = .975, lty = 3)
legend("bottomright", 
       legend = c("Low n", "Moderate n", "High n"),
       col = colors,  
       pch = 19)

```

## Experiment 3: forward simulation

```{r}
#| echo: false
#| fig-width: 6
#| fig-height: 4
simulate_raw_data <- function(n_sims = 100, n_trials = 10, 
                              mu = 0.7, tau_values = c(0.35, 0.7, 1.4)) {
  
  results <- map_df(tau_values, function(tau) {
    map_df(1:n_sims, function(sim) {
      theta <- rnorm(n_trials, mu, tau)
      tibble(
        tau = tau,
        sim = sim,
        theta = theta,
        mean_theta = mean(theta),
        prop_pos = mean(theta > 0),
        sd_theta = sd(theta)
      )
    })
  })
  
  results$tau <- factor(results$tau, 
                        levels = c(0.35, 0.7, 1.4),
                        labels = c("Low τ", "Moderate τ", "High τ"))
  return(results)
}

set.seed(123)
raw_results <- simulate_raw_data()

ggplot(raw_results, aes(x = tau, y = theta, color = tau)) +
  geom_point(alpha = 0.5, position = "jitter") +
  labs(x = NULL,
       y = "theta",
       color = "Between-study\nvariation",
       title = "Direct simulation of study effects",
       subtitle = "100 simulations of ten trials") +
  theme_minimal() +
  ggokabeito::scale_color_okabe_ito()

df <- raw_results %>% 
  group_by(tau, sim) %>% 
  summarise(mean_theta = mean(theta),
            sd_theta = sd(theta))

ggplot(df, aes(x = tau, y = mean_theta/sd_theta, color = tau)) +
  geom_point(alpha = 0.5, position = "jitter") +
  labs(x = NULL,
       y = "z-value",
       color = "Between-study\nvariation",
       title = "Direct simulation of study effects",
       subtitle = "100 z-values") +
  theme_minimal() +
  ggokabeito::scale_color_okabe_ito()

```
